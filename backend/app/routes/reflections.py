"""
íšŒê³  v3 ì‹œìŠ¤í…œ API
- Micro Log (ì´ˆë¼ì´íŠ¸ ê¸°ë¡)
- Preference Pulse (ì·¨í–¥ íƒì§€)
- Action Nudge (í–‰ë™ ì œì•ˆ)
- Story View (ìŠ¤í† ë¦¬ ìƒì„±)
"""

from fastapi import APIRouter, Depends, Query, HTTPException
from pydantic import BaseModel
from typing import Optional, List
from datetime import datetime, date, timedelta
from app.database import get_supabase, ensure_reflection_table
from app.utils.auth import get_current_user_id
from collections import Counter
import logging

logger = logging.getLogger(__name__)
router = APIRouter()

# ===== Pydantic Models =====

class MicroLogCreate(BaseModel):
    """ì´ˆë¼ì´íŠ¸ ê¸°ë¡ ìƒì„± ìš”ì²­"""
    activity_type: str  # contest | club | project | internship | study | etc
    memo: Optional[str] = None
    mood_compare: str  # worse | same | better
    reason: Optional[str] = None  # positive_001~006 | negative_001~006
    tags: Optional[List[str]] = []
    date: date
    space_id: Optional[str] = None  # ìŠ¤í˜ì´ìŠ¤ ì—°ë™

# ===== Micro Log Endpoints =====

@router.post("/micro")
async def create_micro_log(
    log_data: MicroLogCreate,
    user_id: str = Depends(get_current_user_id)
):
    """ì´ˆë¼ì´íŠ¸ ê¸°ë¡ ì‘ì„±"""
    try:
        supabase = get_supabase()
        
        # ìœ íš¨ì„± ê²€ì¦
        if log_data.activity_type not in ['contest', 'club', 'project', 'internship', 'study', 'etc']:
            return {
                "success": False,
                "data": None,
                "error": {
                    "code": "INVALID_ACTIVITY_TYPE",
                    "message": "ì˜ëª»ëœ í™œë™ ìœ í˜•ì…ë‹ˆë‹¤"
                }
            }
        
        if log_data.mood_compare not in ['worse', 'same', 'better']:
            return {
                "success": False,
                "data": None,
                "error": {
                    "code": "INVALID_MOOD_COMPARE",
                    "message": "ì˜ëª»ëœ ê¸°ë¶„ ë¹„êµê°’ì…ë‹ˆë‹¤"
                }
            }
        
        # mood_compareê°€ 'same'ì´ ì•„ë‹ ë•Œ reason í•„ìˆ˜
        if log_data.mood_compare != 'same' and not log_data.reason:
            return {
                "success": False,
                "data": None,
                "error": {
                    "code": "REASON_REQUIRED",
                    "message": "ê¸°ë¶„ ì´ìœ ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”"
                }
            }
        
        # memo ê¸¸ì´ ì²´í¬
        if log_data.memo and len(log_data.memo) > 500:
            return {
                "success": False,
                "data": None,
                "error": {
                    "code": "MEMO_TOO_LONG",
                    "message": "ë©”ëª¨ëŠ” 500ì ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”"
                }
            }
        
        # ë¡œê·¸ ì €ì¥
        insert_data = {
            "user_id": user_id,
            "activity_type": log_data.activity_type,
            "memo": log_data.memo,
            "mood_compare": log_data.mood_compare,
            "reason": log_data.reason,
            "tags": log_data.tags or [],
            "date": str(log_data.date),
            "space_id": log_data.space_id
        }
        
        response = supabase.table("micro_logs").insert(insert_data).execute()
        
        if not response.data:
            return {
                "success": False,
                "data": None,
                "error": {
                    "code": "CREATE_FAILED",
                    "message": "ê¸°ë¡ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
                }
            }
        
        log = response.data[0]
        
        return {
            "success": True,
            "data": {
                "id": log["id"],
                "user_id": log["user_id"],
                "activity_type": log["activity_type"],
                "memo": log["memo"],
                "mood_compare": log["mood_compare"],
                "reason": log["reason"],
                "tags": log["tags"],
                "date": log["date"],
                "created_at": log["created_at"]
            },
            "error": None
        }
    except Exception as e:
        return {
            "success": False,
            "data": None,
            "error": {
                "code": "INTERNAL_ERROR",
                "message": str(e)
            }
        }


@router.delete("/micro/{log_id}")
async def delete_micro_log(
    log_id: str,
    user_id: str = Depends(get_current_user_id)
):
    """ë‹¨ì¼ ë§ˆì´í¬ë¡œ ë¡œê·¸ ì‚­ì œ"""
    try:
        supabase = get_supabase()
        # ì†Œìœ ì í™•ì¸ ë° ì‚­ì œ
        check = supabase.table("micro_logs").select("id, user_id").eq("id", log_id).single().execute()
        if not check.data:
            raise HTTPException(status_code=404, detail="ë§ˆì´í¬ë¡œ ë¡œê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        if check.data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="ì‚­ì œ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤")

        res = supabase.table("micro_logs").delete().eq("id", log_id).eq("user_id", user_id).execute()
        return {"success": True, "data": {"id": log_id}, "error": None}
    except HTTPException:
        raise
    except Exception as e:
        return {"success": False, "data": None, "error": {"code": "INTERNAL_ERROR", "message": str(e)}}

@router.get("/micro")
async def get_micro_logs(
    user_id: str = Depends(get_current_user_id),
    limit: int = Query(20, le=100),
    offset: int = Query(0, ge=0),
    date_from: Optional[date] = None,
    date_to: Optional[date] = None,
    activity_type: Optional[str] = None
):
    """ì´ˆë¼ì´íŠ¸ ê¸°ë¡ ëª©ë¡ ì¡°íšŒ"""
    try:
        supabase = get_supabase()
        
        # ì¿¼ë¦¬ ë¹Œë“œ
        query = supabase.table("micro_logs").select("*", count="exact").eq("user_id", user_id)
        
        # ë‚ ì§œ í•„í„°
        if date_from:
            query = query.gte("date", str(date_from))
        if date_to:
            query = query.lte("date", str(date_to))
        
        # í™œë™ ìœ í˜• í•„í„°
        if activity_type:
            query = query.eq("activity_type", activity_type)
        
        # ì •ë ¬ ë° í˜ì´ì§€ë„¤ì´ì…˜
        query = query.order("date", desc=True).order("created_at", desc=True)
        query = query.range(offset, offset + limit - 1)
        
        response = query.execute()
        
        return {
            "success": True,
            "data": {
                "logs": response.data or [],
                "total": response.count or 0,
                "limit": limit,
                "offset": offset
            },
            "error": None
        }
    except Exception as e:
        return {
            "success": False,
            "data": None,
            "error": {
                "code": "INTERNAL_ERROR",
                "message": str(e)
            }
        }

# ===== Stats Endpoint =====

@router.get("/stats")
async def get_reflection_stats(
    user_id: str = Depends(get_current_user_id),
    period: str = Query("week", regex="^(week|month)$")
):
    """íšŒê³  í†µê³„ ì¡°íšŒ"""
    try:
        supabase = get_supabase()
        
        # ê¸°ê°„ ê³„ì‚°
        days = 7 if period == "week" else 30
        start_date = datetime.now().date() - timedelta(days=days)
        
        # ê¸°ê°„ ë‚´ ë¡œê·¸ ì¡°íšŒ
        response = supabase.table("micro_logs") \
            .select("*") \
            .eq("user_id", user_id) \
            .gte("date", str(start_date)) \
            .execute()
        
        logs = response.data or []
        total_logs = len(logs)
        
        if total_logs == 0:
            return {
                "success": True,
                "data": {
                    "period": period,
                    "total_logs": 0,
                    "positive_logs": 0,
                    "neutral_logs": 0,
                    "negative_logs": 0,
                    "growth_trend": 0,
                    "most_active_type": None,
                    "activity_distribution": {},
                    "top_tags": []
                },
                "error": None
            }
        
        # í†µê³„ ê³„ì‚°
        positive_logs = len([log for log in logs if log["mood_compare"] == "better"])
        neutral_logs = len([log for log in logs if log["mood_compare"] == "same"])
        negative_logs = len([log for log in logs if log["mood_compare"] == "worse"])
        
        # ì„±ì¥ íŠ¸ë Œë“œ (ê¸ì • - ë¶€ì •) / ì „ì²´ * 100
        growth_trend = round(((positive_logs - negative_logs) / total_logs) * 100, 1)
        
        # í™œë™ ìœ í˜• ë¶„í¬
        activity_distribution = dict(Counter([log["activity_type"] for log in logs]))
        most_active_type = max(activity_distribution, key=activity_distribution.get) if activity_distribution else None
        
        # Top íƒœê·¸
        all_tags = []
        for log in logs:
            if log.get("tags"):
                all_tags.extend(log["tags"])
        
        tag_counts = Counter(all_tags)
        top_tags = [{"tag": tag, "count": count} for tag, count in tag_counts.most_common(5)]
        
        return {
            "success": True,
            "data": {
                "period": period,
                "total_logs": total_logs,
                "positive_logs": positive_logs,
                "neutral_logs": neutral_logs,
                "negative_logs": negative_logs,
                "growth_trend": growth_trend,
                "most_active_type": most_active_type,
                "activity_distribution": activity_distribution,
                "top_tags": top_tags
            },
            "error": None
        }
    except Exception as e:
        return {
            "success": False,
            "data": None,
            "error": {
                "code": "INTERNAL_ERROR",
                "message": str(e)
            }
        }

# ===== Story View Endpoint =====

@router.get("/story")
async def get_reflection_story(
    user_id: str = Depends(get_current_user_id),
    period: str = Query("week", regex="^(week|month|quarter)$")
):
    """ìŠ¤í† ë¦¬ ë·° ìƒì„±"""
    try:
        supabase = get_supabase()
        
        # ê¸°ê°„ ê³„ì‚°
        if period == "week":
            days = 7
            period_label = "ì´ë²ˆ ì£¼"
        elif period == "month":
            days = 30
            period_label = "ì´ë²ˆ ë‹¬"
        else:  # quarter
            days = 90
            period_label = "ì´ë²ˆ ë¶„ê¸°"
        
        start_date = datetime.now().date() - timedelta(days=days)
        
        # ê¸°ê°„ ë‚´ ë¡œê·¸ ì¡°íšŒ
        response = supabase.table("micro_logs") \
            .select("*") \
            .eq("user_id", user_id) \
            .gte("date", str(start_date)) \
            .order("date", desc=False) \
            .execute()
        
        logs = response.data or []
        
        if not logs:
            return {
                "success": True,
                "data": {
                    "period_label": period_label,
                    "total_days": days,
                    "activity_summary": [],
                    "positive_patterns": [],
                    "negative_patterns": [],
                    "strength_analysis": "ì•„ì§ ê¸°ë¡ì´ ë¶€ì¡±í•´ìš”. ë” ë§ì€ ê²½í—˜ì„ ê¸°ë¡í•´ë³´ì„¸ìš”!",
                    "suggested_tracks": [],
                    "next_suggestion": None
                },
                "error": None
            }
        
        # í™œë™ ìš”ì•½
        activity_counts = Counter([log["activity_type"] for log in logs])
        activity_icons = {
            "contest": "ğŸ†",
            "club": "ğŸ‘¥",
            "project": "ğŸ’¼",
            "internship": "ğŸ’¼",
            "study": "ğŸ“š",
            "etc": "âœ¨"
        }
        activity_labels = {
            "contest": "ê³µëª¨ì „/ëŒ€ì™¸í™œë™",
            "club": "í•™íšŒ/ë™ì•„ë¦¬",
            "project": "í”„ë¡œì íŠ¸",
            "internship": "ì¸í„´/ì•„ë¥´ë°”ì´íŠ¸",
            "study": "ìê²©ì¦/ê³µë¶€",
            "etc": "ê¸°íƒ€"
        }
        activity_summary = [
            {
                "type": act_type,
                "count": count,
                "icon": activity_icons.get(act_type, "âœ¨"),
                "label": activity_labels.get(act_type, "ê¸°íƒ€")
            }
            for act_type, count in activity_counts.most_common()
        ]
        
        # ê¸ì • íŒ¨í„´ ë¶„ì„
        positive_logs = [log for log in logs if log["mood_compare"] == "better"]
        positive_patterns = []
        
        if positive_logs:
            # reason ë¹ˆë„ ë¶„ì„
            reason_map = {
                "positive_001": "ì‚¬ëŒë“¤ê³¼ ì˜ê²¬ ì£¼ê³ ë°›ëŠ” í™œë™ì—ì„œ ì—ë„ˆì§€ë¥¼ ì–»ì–´ìš”",
                "positive_002": "ìƒˆë¡œìš´ ê²ƒì„ ë°°ìš°ëŠ” ê³¼ì •ì„ ì¦ê²¨ìš”",
                "positive_003": "ìì‹ ì˜ ê°•ì ì„ ë°œíœ˜í•  ìˆ˜ ìˆëŠ” í™œë™ì—ì„œ ë¹›ë‚˜ìš”",
                "positive_004": "ëˆ„êµ°ê°€ì—ê²Œ ë„ì›€ì´ ë˜ëŠ” ì¼ì—ì„œ ë³´ëŒì„ ëŠê»´ìš”",
                "positive_005": "ì¼ì´ ìˆ ìˆ  í’€ë¦´ ë•Œ ê¸°ë¶„ì´ ì¢‹ì•„ì ¸ìš”",
                "positive_006": "ì„±ê³¼ë¥¼ ì¸ì •ë°›ì„ ë•Œ ë¿Œë“¯í•¨ì„ ëŠê»´ìš”"
            }
            reason_counts = Counter([log["reason"] for log in positive_logs if log.get("reason")])
            positive_patterns = [
                reason_map.get(reason, "ê¸ì •ì ì¸ ê²½í—˜ì„ ë§ì´ í•˜ê³  ìˆì–´ìš”")
                for reason, _ in reason_counts.most_common(3)
            ]
        
        # ë¶€ì • íŒ¨í„´ ë¶„ì„
        negative_logs = [log for log in logs if log["mood_compare"] == "worse"]
        negative_patterns = []
        
        if negative_logs:
            reason_map = {
                "negative_001": "ìƒê°ë³´ë‹¤ ì˜ ì•ˆ í’€ë¦¬ëŠ” ìƒí™©ì—ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ì•„ìš”",
                "negative_002": "ì‚¬ëŒë“¤ê³¼ ì˜ê²¬ì´ ì•ˆ ë§ì„ ë•Œ ì–´ë ¤ì›€ì„ ëŠê»´ìš”",
                "negative_003": "ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…ì—ì„œ ì§€ì³ìš”",
                "negative_004": "ìì‹ ì´ ëª»í•˜ëŠ” ë¶€ë¶„ì´ ë“œëŸ¬ë‚  ë•Œ í˜ë“¤ì–´í•´ìš”",
                "negative_005": "í•˜ê¸° ì‹«ì€ ì¼ì„ ì–µì§€ë¡œ í•  ë•Œ ì—ë„ˆì§€ê°€ ë–¨ì–´ì ¸ìš”",
                "negative_006": "ê²°ê³¼ê°€ ê¸°ëŒ€ì— ëª» ë¯¸ì¹  ë•Œ ì‹¤ë§í•´ìš”"
            }
            reason_counts = Counter([log["reason"] for log in negative_logs if log.get("reason")])
            negative_patterns = [
                reason_map.get(reason, "ì–´ë ¤ìš´ ê²½í—˜ë„ ìˆì—ˆì–´ìš”")
                for reason, _ in reason_counts.most_common(2)
            ]
        
        # ê°•ì  ë¶„ì„ (ë¹ˆë„ ë†’ì€ íƒœê·¸ ê¸°ë°˜)
        all_positive_tags = []
        for log in positive_logs:
            if log.get("tags"):
                all_positive_tags.extend(log["tags"])
        
        strength_analysis = "ì•„ì§ íŒ¨í„´ì´ ëª…í™•í•˜ì§€ ì•Šì•„ìš”. ë” ë§ì€ ê²½í—˜ì„ ê¸°ë¡í•´ë³´ì„¸ìš”!"
        if all_positive_tags:
            top_tags = [tag for tag, _ in Counter(all_positive_tags).most_common(3)]
            strength_analysis = f"**{', '.join(top_tags)}** ë¶„ì•¼ì—ì„œ ê°•ì ì„ ë³´ì´ê³  ìˆì–´ìš”."
        
        # ì¶”ì²œ ì§„ë¡œ íŠ¸ë™ (ê°„ë‹¨ ë²„ì „ - AI í†µí•© ì‹œ ê°œì„ )
        suggested_tracks = [
            {
                "track": "ê¸°íš/ì „ëµ",
                "score": 75,
                "reason": "ì²´ê³„ì ì¸ í™œë™ ê¸°ë¡ê³¼ ë¶„ì„ ëŠ¥ë ¥"
            }
        ]
        
        # ë‹¤ìŒ í–‰ë™ ì œì•ˆ
        next_suggestion = {
            "title": "ë” ë‹¤ì–‘í•œ ê²½í—˜ ìŒ“ê¸°",
            "description": "ì§€ê¸ˆê¹Œì§€ì˜ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ, ìƒˆë¡œìš´ ë¶„ì•¼ì—ë„ ë„ì „í•´ë³´ì„¸ìš”.",
            "action": "ì¶”ì²œ í™œë™ ë³´ëŸ¬ê°€ê¸°",
            "recommended_activities": []
        }
        
        return {
            "success": True,
            "data": {
                "period_label": period_label,
                "total_days": days,
                "activity_summary": activity_summary,
                "positive_patterns": positive_patterns,
                "negative_patterns": negative_patterns,
                "strength_analysis": strength_analysis,
                "suggested_tracks": suggested_tracks,
                "next_suggestion": next_suggestion
            },
            "error": None
        }
    except Exception as e:
        return {
            "success": False,
            "data": None,
            "error": {
                "code": "INTERNAL_ERROR",
                "message": str(e)
            }
        }

# ===== STAR íšŒê³  ì €ì¥ ì—”ë“œí¬ì¸íŠ¸ =====

class StarReflectionCreate(BaseModel):
    """STAR íšŒê³  ì €ì¥ ìš”ì²­"""
    template_id: str
    template_name: str
    answers: dict  # {situation, task, action, result}
    competencies: List[str]  # ì—­ëŸ‰ëª… ë¦¬ìŠ¤íŠ¸
    competency_scores: dict  # {ì—­ëŸ‰ëª…: ì ìˆ˜}
    competency_analysis: dict  # ì „ì²´ ë¶„ì„ ê²°ê³¼ (evidence, reason, analysis í¬í•¨)

@router.post("")
async def create_reflection(
    reflection_data: StarReflectionCreate,
    user_id: str = Depends(get_current_user_id)
):
    """íšŒê³  ì €ì¥ (ëª¨ë“  í…œí”Œë¦¿ ì§€ì›)"""
    try:
        supabase = get_supabase()
        template_id = reflection_data.template_id
        
        # í†µí•© reflections í…Œì´ë¸” ì‚¬ìš© (ëª¨ë“  í…œí”Œë¦¿ ì§€ì›)
        table_name = await ensure_reflection_table(template_id)
        
        # ì €ì¥í•  ë°ì´í„° ì¤€ë¹„
        insert_data = {
            "user_id": user_id,
            "template_id": reflection_data.template_id,
            "template_name": reflection_data.template_name,
            "answers": reflection_data.answers,
            "competencies": reflection_data.competencies,
            "competency_scores": reflection_data.competency_scores,
            "competency_analysis": reflection_data.competency_analysis,
            "created_at": datetime.now().isoformat()
        }
        
        logger.info(f"ì €ì¥ ì‹œë„: í…Œì´ë¸”={table_name}, í…œí”Œë¦¿={template_id}, ì‚¬ìš©ì={user_id}")
        
        # í†µí•© í…Œì´ë¸”ì— ì €ì¥
        response = supabase.table(table_name).insert(insert_data).execute()
        
        if not response.data:
            return {
                "success": False,
                "data": None,
                "error": {
                    "code": "CREATE_FAILED",
                    "message": "íšŒê³  ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
                }
            }
        
        reflection = response.data[0]
        logger.info(f"ì €ì¥ ì„±ê³µ: ID={reflection.get('id')}, í…œí”Œë¦¿={template_id}")
        
        return {
            "success": True,
            "data": {
                "id": reflection["id"],
                "user_id": reflection["user_id"],
                "template_id": reflection["template_id"],
                "template_name": reflection["template_name"],
                "created_at": reflection["created_at"]
            },
            "error": None
        }
    except Exception as e:
        logger.exception("íšŒê³  ì €ì¥ ì˜¤ë¥˜")
        return {
            "success": False,
            "data": None,
            "error": {
                "code": "INTERNAL_ERROR",
                "message": str(e)
            }
        }

# ===== ì´ì „ reflections ì—”ë“œí¬ì¸íŠ¸ (í•˜ìœ„ í˜¸í™˜ì„±) =====

@router.get("")
async def list_reflections(
    user_id: str = Depends(get_current_user_id),
    limit: int = Query(50, le=100),
    template_id: Optional[str] = None
):
    """íšŒê³  ëª©ë¡ ì¡°íšŒ (ëª¨ë“  í…œí”Œë¦¿ ì§€ì›)"""
    try:
        supabase = get_supabase()
        
        # í†µí•© reflections í…Œì´ë¸”ì—ì„œ ì¡°íšŒ
        query = supabase.table("reflections") \
            .select("*") \
            .eq("user_id", user_id)
        
        # íŠ¹ì • í…œí”Œë¦¿ í•„í„°ë§
        if template_id:
            query = query.eq("template_id", template_id)
            logger.info(f"ì¡°íšŒ: í…œí”Œë¦¿={template_id}, ì‚¬ìš©ì={user_id}")
        else:
            logger.info(f"ì¡°íšŒ: ëª¨ë“  í…œí”Œë¦¿, ì‚¬ìš©ì={user_id}")
        
        response = query \
            .order("created_at", desc=True) \
            .limit(limit) \
            .execute()
        
        all_reflections = response.data or []
        logger.info(f"ì¡°íšŒ ê²°ê³¼: {len(all_reflections)}ê°œ")
        
        return {
            "success": True,
            "data": {
                "reflections": all_reflections
            },
            "error": None
        }
    except Exception as e:
        logger.exception("íšŒê³  ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜")
        return {
            "success": False,
            "data": None,
            "error": {
                "code": "INTERNAL_ERROR",
                "message": str(e)
            }
        }


@router.delete("/{reflection_id}")
async def delete_reflection(
    reflection_id: str,
    user_id: str = Depends(get_current_user_id)
):
    """ë‹¨ì¼ AI íšŒê³ (Reflection) ì‚­ì œ"""
    try:
        supabase = get_supabase()

        # ì†Œìœ ì í™•ì¸
        check = supabase.table("reflections").select("id, user_id").eq("id", reflection_id).single().execute()
        if not check.data:
            raise HTTPException(status_code=404, detail="íšŒê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        if check.data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="ì‚­ì œ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤")

        # ì‚­ì œ
        supabase.table("reflections").delete().eq("id", reflection_id).eq("user_id", user_id).execute()

        return {"success": True, "data": {"id": reflection_id}, "error": None}
    except HTTPException:
        raise
    except Exception as e:
        logger.exception("íšŒê³  ì‚­ì œ ì˜¤ë¥˜")
        return {"success": False, "data": None, "error": {"code": "INTERNAL_ERROR", "message": str(e)}}

@router.get("/growth-stats")
async def get_growth_stats(user_id: str = Depends(get_current_user_id)):
    """ì„±ì¥ í†µê³„ ì¡°íšŒ (í•˜ìœ„ í˜¸í™˜)"""
    return {
        "success": True,
        "data": {
            "avg_progress": 0,
            "completion_rate": 0,
            "keyword_count": 0,
            "project_completion": 0
        },
        "error": None
    }
